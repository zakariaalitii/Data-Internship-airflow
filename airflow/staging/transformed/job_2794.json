{
    "job": {
        "title": "Data Scientist",
        "industry": "Information Technology and Services",
        "description": "&lt;p&gt;Data Scientists are responsible for cleaning, transforming, enriching, and analyzing vast amounts of raw data from various systems using Apache Spark and other analytics packages to develop valuable features and to provide ready-to-use data to stakeholders for robust downstream analysis. They analyze data for correlations to identify trends and predictive power, and build, maintain, and deploy predictive models. Data Scientists work with analysts to understand business needs and requirements, and data engineers to implement scalable pipelines for ETL, model training, and scoring. They service both ad-hoc requests as well as core pipeline development. The ideal candidate has a passion for discovering insight hidden in large data sets and working with stakeholders to improve business outcomes. They keep up with the latest technology including the latest versions of spark, new analytical packages, etc. They must have a proven ability to drive business results with their data-based insights and be comfortable working with a wide range of stakeholders and functional teams.&lt;/p&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Core Responsibilities&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Collaborate with product management and engineering departments to understand company needs and devise possible solutions&lt;/li&gt;&lt;li&gt;Mine and analyze data from company databases to drive optimization and improvement of product development, marketing techniques and business strategies&lt;/li&gt;&lt;li&gt;Communicate results and ideas to key decision makers&lt;/li&gt;&lt;li&gt;Research and develop predictive models for data analysis&lt;/li&gt;&lt;li&gt;Optimize joint development efforts through appropriate database use and project design&lt;/li&gt;&lt;li&gt;Assess the effectiveness and accuracy of new data sources and data gathering techniques&lt;/li&gt;&lt;li&gt;Develop custom data transformations, models, algorithms to apply to data sets&lt;/li&gt;&lt;li&gt;Use predictive modeling to increase and optimize customer experiences, revenue generation, ad targeting and other business outcomes&lt;/li&gt;&lt;li&gt;Develop processes and tools to monitor and analyze model performance and data accuracy&lt;/li&gt;&lt;li&gt;Create high-performance pipelines in Apache Spark for data transformation, aggregation, and model training&lt;/li&gt;&lt;li&gt;Develop and share well documented analysis in data science notebook solutions like Jupyter&lt;/li&gt;&lt;li&gt;Write documentation with all code&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Basic Qualifications&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Excellent communication and interpersonal skills&lt;/li&gt;&lt;li&gt;Knowledge of agile methodologies and tools (e.g. Scrum, JIRA).&lt;/li&gt;&lt;li&gt;Basic system administration skills in both a Windows and Linux environment&lt;/li&gt;&lt;li&gt;Bachelor\u2019s degree in Computer Science, Statistics, Applied Math or related field&lt;/li&gt;&lt;li&gt;3+ years practical experience with Apache Spark, ETL, machine learning, data processing, and data analytics&lt;/li&gt;&lt;li&gt;Strong experience with Python and Bash shell scripting&lt;/li&gt;&lt;li&gt;Strong experience with Apache Spark and MLflow&lt;/li&gt;&lt;li&gt;Strong experience with AWS and/or Google Cloud Platform&lt;/li&gt;&lt;li&gt;Experience training, deploying, monitoring, and updating machine learning models&lt;/li&gt;&lt;li&gt;Knowledge of a variety of machine learning techniques, including clustering, decision trees, random forest, boosting, text mining, and neural networks, and their real-world advantages and drawbacksGLM/Regression, Random Forest, Boosting, Trees, text mining, social network analysis, etc.&lt;/li&gt;&lt;li&gt;Experience with multiple machine learning libraries, including XGBoost, Scikit-learn, TensorFlow, and PyTorch&lt;/li&gt;&lt;li&gt;Experience working with and creating data architectures&lt;/li&gt;&lt;li&gt;The ability to teach and train others in the methodologies and practices used in data science&lt;/li&gt;&lt;li&gt;Familiarity with Git and code versioning practices&lt;/li&gt;&lt;li&gt;Familiarity with the Atlassian product suite, including JIRA and Confluence&lt;/li&gt;&lt;li&gt;A drive to learn and master new technologies and techniques&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Preferred Qualifications&lt;/strong&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Strong experience with Scala&lt;/li&gt;&lt;li&gt;5+ years practical experience with Apache Spark (Scala and Python), ETL, machine learning, data processing, and data analytics&lt;/li&gt;&lt;li&gt;Strong experience with Apache Spark 3.x, including query tuning and performance optimization&lt;/li&gt;&lt;li&gt;Master\u2019s or Doctoral Degree in Computer Science, Statistics, Applied Math or related field&lt;/li&gt;&lt;li&gt;Strong experience with AWS EMR, Glue, and Athena&lt;/li&gt;&lt;li&gt;Experience working with healthcare data, specifically healthcare insurance claims data&lt;/li&gt;&lt;/ul&gt;",
        "employment_type": "FULL_TIME",
        "date_posted": "2021-08-05T12:38:39.000Z"
    },
    "company": {
        "name": "Bridge Technical Talent",
        "link": "https://www.linkedin.com/company/bridge-technical-talent"
    },
    "education": {
        "required_credential": "bachelor degree"
    },
    "experience": {
        "months_of_experience": 60,
        "seniority_level": null
    },
    "salary": {
        "currency": null,
        "min_value": null,
        "max_value": null,
        "unit": null
    },
    "location": {
        "country": "US",
        "locality": "Connecticut",
        "region": "United States",
        "postal_code": "06450",
        "street_address": null,
        "latitude": 41.575153,
        "longitude": -72.73828
    }
}