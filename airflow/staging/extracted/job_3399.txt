{"@context": "http://schema.org", "@type": "JobPosting", "datePosted": "2021-08-13T13:59:23.000Z", "description": "&lt;br&gt;Hi, &lt;br&gt;&lt;br&gt;We are have an opportunity for the below job. We will request you to revert back with your resume. &lt;br&gt;&lt;br&gt;Position: Data Scientist&lt;br&gt;Location: Plano TX (Currently Remote \u2013 Will be Onsite until the further announcement.&lt;br&gt;Duration: Long Term&lt;br&gt;Job Description:&lt;br&gt;&lt;br&gt;Duties to Perform&lt;br&gt;\u2022\tBuild proof-of-concept models using a prototype infrastructure&lt;br&gt;\u2022\tBring proof-of-concept models into production using prototype infrastructure&lt;br&gt;\u2022\tCommunicate shortcomings or improvements to multi-language API for database interaction&lt;br&gt;\u2022\tBuild proof-of-concept feature engineering batch and streaming jobs &lt;br&gt;\u2022\tCreate and present Powerpoint decks describing work to both technical and non-technical audiences&lt;br&gt;\u2022\tAssist in design and brainstorming sessions for prototype capabilities&lt;br&gt;&lt;br&gt;Required Skill &amp; Experience&lt;br&gt;\u2022\tExpert in Azure Cloud (*Machine Learning*: Event Hub/Streaming Analytics, HDI, DB, Azure ML, Azure Log Analytics, Databricks)&lt;br&gt;\u2022\tStrong statistics and machine learning fundamentals&lt;br&gt;\u2022\tDemonstrated experience putting models into real-time production &lt;br&gt;\u2022\tExperience with Python required; R, Scala, and (Java nice to have)&lt;br&gt;\u2022\tExperience with Spark DataFrame and SQL API's required.  Spark streaming/structured streaming are nice to have&lt;br&gt;\u2022\tExperience with Azure Cloud&lt;br&gt;\u2022\tExperience with Databricks(Spark, Delta Lake, MLFlow)&lt;br&gt;\u2022\tExperience with H2O Driverless AI&lt;br&gt;\u2022\tExperience with Kafka/Azure Event Hub&lt;br&gt;\u2022\tStrong Team Player&lt;br&gt;\u2022\tStrong problem-solving skills&lt;br&gt;\u2022\tStrong communication skills and the ability to describe shortcomings in system design&lt;br&gt;\u2022\tA strong desire and ability to learn new tools and technologies.&lt;br&gt;\u2022\tAirflow experience is nice to have&lt;br&gt;&lt;br&gt;Technical Environment&lt;br&gt;\u2022\tAzure&lt;br&gt;\u2022\tSQL / Mongo DB&lt;br&gt;\u2022\tPython / Pyspark&lt;br&gt;\u2022\tKafka / EventHub&lt;br&gt;\u2022\tLinux and Shell Scripting&lt;br&gt;\u2022\tPossibly R, Scala and Java&lt;br&gt;\u2022\tDatabricks&lt;br&gt;\u2022\tAzure data production and consumption tools (Event Hub, Azure Functions, Streaming Analytics,&lt;br&gt;&lt;br&gt;Regards,&lt;br&gt;Suganya &lt;br&gt;&lt;br&gt;What's app :91 9043392040. &lt;br&gt;", "employmentType": "CONTRACTOR", "hiringOrganization": {"@type": "Organization", "name": "To be disclosed", "sameAs": "https://www.linkedin.com/company/to-be-disclosed"}, "identifier": {"@type": "PropertyValue", "name": "To be disclosed"}, "image": null, "industry": "", "jobLocation": {"@type": "Place", "address": {"@type": "PostalAddress", "addressCountry": "US", "addressLocality": "Plano", "addressRegion": "TX", "postalCode": "75093", "streetAddress": null}, "latitude": 33.019695, "longitude": -96.697586}, "skills": "", "title": "Data Scientist", "validThrough": "2021-09-12T13:59:23.000Z", "educationRequirements": {"@type": "EducationalOccupationalCredential", "credentialCategory": "bachelor degree"}}